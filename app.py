import streamlit as st
import tensorflow as tf
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import os
import gdown
from PIL import Image

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ---
st.set_page_config(page_title="AI Sound Analyzer | Sulaiman Kudaimi", layout="wide")

# ØªØµÙ…ÙŠÙ… Ø§Ù„Ù‡ÙŠØ¯Ø± Ø¨Ø§Ø³Ù…Ùƒ
st.markdown(f"""
    <div style="background-color:#003366;padding:20px;border-radius:10px">
    <h1 style="color:white;text-align:center;">ğŸ­ Industrial Machine Health AI</h1>
    <h3 style="color:#e0e0e0;text-align:center;">Designed & Developed by: <b>Sulaiman Kudaimi</b></h3>
    </div>
    """, unsafe_allow_html=True)

st.write("") # Ù…Ø³Ø§ÙØ©

# --- Ø±Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¯Ø±Ø§ÙŠÙ ---
# Ù‚Ù…Øª Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±Ù (ID) Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ Ø£Ø±Ø³Ù„ØªÙ‡
MODEL_URL = 'https://drive.google.com/file/d/1xghQcu2rDtb6Jp4pvGWs0QUcMJM7NFaE/view?usp=drive_link'
MODEL_PATH = 'audio_anomaly_model.h5'

@st.cache_resource
def load_audio_model():
    if not os.path.exists(MODEL_PATH):
        with st.spinner('ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®ÙˆØ§Ø¯Ù… Ø§Ù„Ø¯Ø±Ø§ÙŠÙ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ...'):
            gdown.download(MODEL_URL, MODEL_PATH, quiet=False)
    return tf.keras.models.load_model(MODEL_PATH)

# --- Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„ØµÙˆØ±Ø© ---
def process_audio(audio_file):
    y, sr = librosa.load(audio_file, sr=None)
    S = librosa.feature.melspectrogram(y=y, sr=sr)
    S_db = librosa.power_to_db(S, ref=np.max)
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ø¤Ø´Ø± ÙƒØµÙˆØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
    fig, ax = plt.subplots(figsize=(2, 2))
    librosa.display.specshow(S_db, ax=ax)
    plt.axis('off')
    plt.savefig("temp_spec.png", bbox_inches='tight', pad_inches=0)
    plt.close()
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù…ØµÙÙˆÙØ© ØªØ¯Ø®Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
    img = Image.open("temp_spec.png").convert('RGB').resize((128, 128))
    return np.array(img) / 255.0

# --- ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ---
try:
    model = load_audio_model()
    st.sidebar.success("âœ… AI Engine Connected")
except Exception as e:
    st.error(f"Error loading model: {e}")

# Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù„Ù„ØªØ¬Ø±Ø¨Ø©
st.subheader("ğŸ“¤ Upload Machine Sound (.wav)")
uploaded_file = st.file_uploader("Ù‚Ù… Ø¨Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ù„Ù…Ø§ÙƒÙŠÙ†Ø© (Ù…Ø±ÙˆØ­Ø©ØŒ Ù…Ø¶Ø®Ø©ØŒ Ø¥Ù„Ø®)", type=["wav"])

if uploaded_file is not None:
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("ğŸµ Audio Signal Analysis")
        st.audio(uploaded_file)
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù€ Spectrogram
        features = process_audio(uploaded_file)
        st.image("temp_spec.png", caption="Generated Spectrogram (AI Input)", use_container_width=True)

    with col2:
        st.info("ğŸ¤– AI Diagnostic Result")
        # Ø§Ù„ØªÙˆÙ‚Ø¹
        prediction = model.predict(np.expand_dims(features, axis=0))
        
        # Ù„Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„ÙØ¦Ø§Øª Ù‡ÙŠ [Normal, Abnormal] Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨Ùƒ
        classes = ['Abnormal (Ø¹Ø·Ù„ Ù…ÙƒØªØ´Ù)', 'Normal (Ø­Ø§Ù„Ø© Ø³Ù„ÙŠÙ…Ø©)']
        result = classes[np.argmax(prediction)]
        confidence = np.max(prediction) * 100

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨Ø´ÙƒÙ„ Ø£Ù†ÙŠÙ‚
        if "Normal" in result:
            st.success(f"### Result: {result}")
        else:
            st.error(f"### Result: {result}")
            
        st.metric(label="Confidence Level", value=f"{confidence:.2f}%")
        
        # Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù… Ù„Ù„Ø«Ù‚Ø©
        st.progress(int(confidence))

st.markdown("---")
st.caption("Â© 2026 Industrial AI Systems | Powered by Sulaiman Kudaimi Research")
